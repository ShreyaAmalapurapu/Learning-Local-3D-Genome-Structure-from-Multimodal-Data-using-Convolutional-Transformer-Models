{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Vgjj2Txh7Wie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762982645396,"user_tz":300,"elapsed":14699,"user":{"displayName":"Sneha Bapana","userId":"06343812349805612711"}},"outputId":"ee7a2ce3-0521-4a8e-8136-bd9a58fff0f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":[],"metadata":{"id":"Ll9v-IGK7Yuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================================================\n","# Colab GPU-ready, fast nBins version (paste-and-run)\n","# - Uses GPU for the model\n","# - Uses bigWig nBins stats for FAST per-bin ATAC/CTCF sampling\n","# - Has MAX_SAMPLES guard for quick smoke tests\n","# - Saves per-bin DNA & Epi embeddings to Parquet shards\n","# ================================================================\n","\n","# ---------- Colab installs ----------\n","!pip -q install pyBigWig pyarrow scikit-image\n","\n","# ---------- CONFIG ----------\n","from pathlib import Path\n","\n","# Folder layout expected:\n","#   {CELLTYPE_ROOT}/genomic_features/atac.bw\n","#   {CELLTYPE_ROOT}/genomic_features/ctcf_log2fc.bw\n","#   {CELLTYPE_ROOT}/hic_matrix/chr1.npz, chr2.npz, ...\n","#   {CELLTYPE_ROOT}/../dna_sequence/chr1.fa.gz, chr2.fa.gz, ...\n","#   {CELLTYPE_ROOT}/../centrotelo.bed   (optional)\n","CELLTYPE_ROOT = \"/content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90\"      # <-- EDIT\n","ASSEMBLY      = \"hg38\"\n","CELLTYPE      = \"IMR90\"\n","\n","ATAC_BW       = f\"{CELLTYPE_ROOT}/genomic_features/atac.bw\"\n","CTCF_BW       = f\"{CELLTYPE_ROOT}/genomic_features/ctcf_log2fc.bw\"\n","DNA_DIR       = f\"{CELLTYPE_ROOT}/../dna_sequence\"\n","HIC_DIR       = f\"{CELLTYPE_ROOT}/hic_matrix\"\n","CENTROTELO_BED= f\"{CELLTYPE_ROOT}/../centrotelo.bed\"   # set to None if you don't have it\n","\n","OUT_DIR       = \"/content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings_out\"              # Parquet outputs\n","\n","# Window/bin params (aligned to your dataset)\n","RES_BP        = 10000               # 10 kb\n","WINDOW_BP     = 2_097_152            # ~2.097 Mb (2^21)\n","L_BINS        = int(WINDOW_BP // RES_BP)  # 209\n","SAMPLE_BINS   = 500                  # 5 Mb proposed frame\n","STRIDE_BINS   = 61                   # 500 kb step\n","IMAGE_SCALE   = 256                  # Hi-C resized for fixed-size models (kept for completeness)\n","\n","# Limit how many samples to process (set None to run all)\n","MAX_SAMPLES   = 300                  # <-- change to None for full run\n","\n","# Choose chromosomes (None -> default split; for quick test use [\"chr10\"])\n","CHROMS        = [\"chr10\"]            # <-- edit or set to None\n","\n","# Output sharding\n","ROWS_PER_SHARD= 10_000\n","\n","# Model dimensions\n","DNA_EMB_DIM   = 128\n","EPI_EMB_DIM   = 128\n","\n","# Optional checkpoint (for this simple model). Leave None for random weights.\n","CKPT_PATH     = None\n","\n","# ================================================================\n","# Imports & GPU setup\n","# ================================================================\n","import os, io, gzip, math, random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pyBigWig as pbw\n","from skimage.transform import resize\n","\n","from typing import List, Tuple\n","\n","# Ensure GPU\n","assert torch.cuda.is_available(), \"No GPU detected. In Colab: Runtime > Change runtime type > Hardware accelerator: GPU\"\n","device = torch.device(\"cuda\")\n","torch.backends.cudnn.benchmark = True\n","print(\"Using device:\", device)\n","\n","# ================================================================\n","# Feature I/O helpers (self-contained)\n","# ================================================================\n","class Feature():\n","    def __init__(self, **kwargs):\n","        self.load(**kwargs)\n","    def load(self, **kwargs): raise NotImplementedError\n","    def get(self, *args, **kwargs): raise NotImplementedError\n","    def __len__(self): raise NotImplementedError\n","\n","class HiCFeature(Feature):\n","    def load(self, path=None):\n","        self.hic = self._load_npz(path)\n","    def get(self, start, window=WINDOW_BP, res=RES_BP):\n","        start_bin = int(start / res)\n","        range_bin = int(window / res)\n","        end_bin   = start_bin + range_bin\n","        return self._diag_to_mat(self.hic, start_bin, end_bin)\n","    def _load_npz(self, path):\n","        print(f\"Reading Hi-C: {path}\")\n","        return dict(np.load(path))\n","    def _diag_to_mat(self, ori_load, start, end):\n","        square_len = end - start\n","        diag_load = {}\n","        for diag_i in range(square_len):\n","            diag_load[str(diag_i)]  = ori_load[str(diag_i)][start : start + square_len - diag_i]\n","            diag_load[str(-diag_i)] = ori_load[str(-diag_i)][start : start + square_len - diag_i]\n","        diag_region = []\n","        for diag_i in range(square_len):\n","            row = []\n","            for line_i in range(-diag_i, -diag_i + square_len):\n","                if line_i < 0:\n","                    row.append(diag_load[str(line_i)][line_i + diag_i])\n","                else:\n","                    row.append(diag_load[str(line_i)][diag_i])\n","            diag_region.append(row)\n","        return np.array(diag_region, dtype=np.float32).reshape(square_len, square_len)\n","    def __len__(self):\n","        return len(self.hic['0'])\n","\n","class GenomicFeature(Feature):\n","    # We will not use per-base values here; nBins is used downstream for speed.\n","    def __init__(self, path, norm):\n","        self.path = path\n","        self.norm = norm\n","        print(f\"Feature path: {path}\\nNormalization status: {norm}\")\n","    def load(self, **kwargs): pass\n","    def get(self, *args, **kwargs): raise NotImplementedError(\"Use bigWig nBins path in main loop\")\n","    def length(self, chr_name):\n","        with pbw.open(self.path) as bw:\n","            return bw.chroms(chr_name)\n","\n","class SequenceFeature(Feature):\n","    def load(self, path=None):\n","        self.seq = self._read_seq(path)\n","    def get(self, start, end):\n","        seq = self._slice(self.seq, start, end)\n","        return self._onehot(seq)\n","    def __len__(self):\n","        return len(self.seq)\n","    def _read_seq(self, dna_path):\n","        print(f\"Reading sequence: {dna_path}\")\n","        with gzip.open(dna_path, \"r\") as f:\n","            raw = f.read().decode(\"utf-8\")\n","        raw = raw[raw.find('\\n')+1:].replace('\\n','').lower()\n","        return raw\n","    def _slice(self, seq, start, end):\n","        return seq[start:end]\n","    def _onehot(self, seq):\n","        # [a,t,c,g,n] ordering\n","        enc = {'a':0,'t':1,'c':2,'g':3,'n':4}\n","        idx = np.fromiter((enc.get(ch,4) for ch in seq), dtype=np.int32, count=len(seq))\n","        out = np.zeros((len(seq), 5), dtype=np.float32)\n","        out[np.arange(len(seq)), idx] = 1.0\n","        return out\n","\n","# ================================================================\n","# Datasets\n","# ================================================================\n","class ChromosomeDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    Provides (sequence, features[], Hi-C) windows across a chromosome.\n","    Features[] are placeholders here; we'll fetch ATAC/CTCF via nBins in main.\n","    \"\"\"\n","    def __init__(self, celltype_root, chr_name, omit_regions, feature_list, use_aug=True):\n","        self.use_aug      = use_aug\n","        self.res          = RES_BP\n","        self.bins_float   = WINDOW_BP / self.res\n","        self.image_scale  = IMAGE_SCALE\n","        self.sample_bins  = SAMPLE_BINS\n","        self.stride       = STRIDE_BINS\n","        self.chr_name     = chr_name\n","\n","        print(f\"Loading chromosome {chr_name}…\")\n","        dna_path = f\"{celltype_root}/../dna_sequence/{chr_name}.fa.gz\"\n","        hic_path = f\"{celltype_root}/hic_matrix/{chr_name}.npz\"\n","        self.seq = SequenceFeature(path=dna_path)\n","        self.mat = HiCFeature(path=hic_path)\n","        self.genomic_features = feature_list  # not used for values here; just for length checks\n","\n","        self.omit_regions = omit_regions if omit_regions is not None else np.zeros((0,2), dtype=int)\n","        self._check_lengths()\n","        self.all_intervals = self._get_active_intervals()\n","        self.intervals     = self._filter(self.all_intervals, self.omit_regions)\n","\n","    def __len__(self): return len(self.intervals)\n","\n","    def __getitem__(self, idx):\n","        start, end = self.intervals[idx]\n","        target_size = int(self.bins_float * self.res)\n","\n","        if self.use_aug:\n","            start, end = self._shift_aug(target_size, start, end)\n","        else:\n","            start, end = self._shift_fix(target_size, start, end)\n","\n","        # DNA one-hot [L_bp,5]\n","        seq = self.seq.get(start, end)\n","\n","        # Hi-C region (optional for training workflows)\n","        mat = self.mat.get(start, window=WINDOW_BP, res=self.res)\n","        mat = resize(mat, (self.image_scale, self.image_scale), anti_aliasing=True).astype(np.float32)\n","        mat = np.log1p(mat)\n","\n","        # Optional augmentations on seq & mat (not enabling for val/test speed)\n","        if self.use_aug:\n","            seq = self._gaussian(seq, 0.1)\n","            # reverse/complement + flip mat w.p. 0.5\n","            if np.random.rand() < 0.5:\n","                seq = np.flip(seq, 0).copy()\n","                if np.random.rand() < 0.5:\n","                    a,t,c,g,n = seq[:,0:1], seq[:,1:2], seq[:,2:3], seq[:,3:4], seq[:,4:5]\n","                    seq = np.concatenate([t,a,g,c,n], axis=1)\n","                mat = np.flip(mat, (0,1)).copy()\n","\n","        # features[] placeholder kept for API compatibility\n","        features_placeholder = []\n","        return seq, features_placeholder, mat, start, end\n","\n","    # helpers\n","    def _gaussian(self, arr, std=0.1):\n","        return arr + np.random.randn(*arr.shape).astype(np.float32) * std\n","    def _get_active_intervals(self):\n","        chr_bins = len(self.seq) / self.res\n","        data_size = int((chr_bins - self.sample_bins) / self.stride)\n","        starts = (np.arange(data_size).reshape(-1,1) * self.stride)\n","        intervals_bin = np.concatenate([starts, starts + self.sample_bins], axis=1)\n","        return (intervals_bin * self.res).astype(int)\n","    def _filter(self, intervals, omit_regions):\n","        if omit_regions is None or len(omit_regions)==0:\n","            return intervals.tolist()\n","        valid = []\n","        for start, end in intervals:\n","            start_cond = start <= omit_regions[:,1]\n","            end_cond   = omit_regions[:,0] <= end\n","            if int(np.sum(start_cond * end_cond)) == 0:\n","                valid.append([int(start), int(end)])\n","        return valid\n","    def _shift_aug(self, target_size, start, end):\n","        max_off = max(1, (end - start - target_size))\n","        offset = random.randrange(max_off)\n","        return start + offset, start + offset + target_size\n","    def _shift_fix(self, target_size, start, end):\n","        return start, start + target_size\n","    def _check_lengths(self):\n","        if len(self.genomic_features) > 0:\n","            f0_len = self.genomic_features[0].length(self.chr_name)\n","            assert len(self.seq) == f0_len, f\"Sequence {len(self.seq)} vs first feature {f0_len} mismatch.\"\n","        dna_bins = len(self.seq) / self.res\n","        hic_bins = len(self.mat)\n","        assert abs(dna_bins - hic_bins) < 2, f\"DNA bins {dna_bins} vs Hi-C bins {hic_bins} mismatch.\"\n","\n","class GenomeDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    Default split:\n","      train -> autosomes except chr10/chr15 and excluding chrX\n","      val   -> chr10\n","      test  -> chr15\n","    \"\"\"\n","    def __init__(self, celltype_root, assembly, feat_dicts, mode=\"val\", use_aug=False):\n","        self.data_root = celltype_root\n","        self.use_aug   = use_aug if mode==\"train\" else False\n","\n","        self.chr_names = self._enumerate_chrs(assembly)\n","        if mode == \"train\":\n","            for drop in [\"chr10\",\"chr15\",\"chrX\"]:\n","                if drop in self.chr_names:\n","                    self.chr_names.remove(drop)\n","        elif mode == \"val\":\n","            self.chr_names = [\"chr10\"]\n","        elif mode == \"test\":\n","            self.chr_names = [\"chr15\"]\n","        else:\n","            raise ValueError(f\"Unknown mode: {mode}\")\n","\n","        # Override with manual CHROMS if provided\n","        global CHROMS\n","        if CHROMS is not None:\n","            self.chr_names = CHROMS\n","\n","        # Feature objects (for length checks; values fetched via nBins later)\n","        self.genomic_features = []\n","        for d in feat_dicts.values():\n","            self.genomic_features.append(GenomicFeature(f\"{celltype_root}/genomic_features/{Path(d['file_name']).name}\", d['norm']))\n","\n","        # Omit regions\n","        if CENTROTELO_BED and os.path.exists(CENTROTELO_BED):\n","            omit_dict = self._proc_bed(CENTROTELO_BED)\n","        else:\n","            print(\"No centrotelo bed provided; proceeding without region masking.\")\n","            omit_dict = {name: np.zeros((0,2), dtype=int) for name in self.chr_names}\n","\n","        print(\"Loading chromosome datasets…\")\n","        self.chr_data, self.lengths = {}, []\n","        for chr_name in self.chr_names:\n","            ds = ChromosomeDataset(self.data_root, chr_name, omit_dict.get(chr_name, None),\n","                                   self.genomic_features, use_aug=self.use_aug)\n","            self.chr_data[chr_name] = ds\n","            self.lengths.append(len(ds))\n","        print(\"Chromosome datasets loaded.\")\n","        self.ranges = self._ranges(self.lengths)\n","\n","    def __len__(self): return sum(self.lengths)\n","\n","    def __getitem__(self, idx):\n","        chr_name, local_idx = self._locate(idx)\n","        seq, features_placeholder, mat, start, end = self.chr_data[chr_name][local_idx]\n","        return seq, features_placeholder, mat, start, end, chr_name, local_idx\n","\n","    # helpers\n","    def _enumerate_chrs(self, assembly):\n","        print(f\"Using assembly: {assembly}\")\n","        if assembly in [\"hg38\",\"hg19\"]:\n","            nums = list(range(1,23))\n","        elif assembly in [\"mm10\",\"mm9\"]:\n","            nums = list(range(1,20))\n","        else:\n","            raise ValueError(f\"Assembly {assembly} unknown.\")\n","        return [f\"chr{n}\" for n in nums] + [\"chrX\"]\n","    def _ranges(self, lengths):\n","        cur, out = 0, []\n","        for L in lengths:\n","            out.append([cur, cur + L - 1])\n","            cur += L\n","        return out\n","    def _locate(self, idx):\n","        for i, (s,e) in enumerate(self.ranges):\n","            if s <= idx <= e:\n","                return self.chr_names[i], idx - s\n","        raise IndexError(idx)\n","    def _proc_bed(self, bed_path):\n","        df = pd.read_csv(bed_path, sep=\"\\t\", names=[\"chr\",\"start\",\"end\"])\n","        return {k: v[[\"start\",\"end\"]].to_numpy(dtype=int) for k,v in df.groupby(\"chr\")}\n","\n","# ================================================================\n","# Model (dual encoders) + hooks\n","# ================================================================\n","class SeqEncoder(nn.Module):\n","    def __init__(self, in_channels=4, emb_dim=DNA_EMB_DIM):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=15, padding=7)\n","        self.conv2 = nn.Conv1d(64, 128, kernel_size=7, padding=3)\n","        self.proj  = nn.Conv1d(128, emb_dim, kernel_size=1)\n","    def forward(self, x_base, res_bp=RES_BP, l_bins=L_BINS):\n","        # x_base: [B,4,L_bp] -> trim to multiple of bins\n","        L_bp = x_base.shape[-1]\n","        eff  = l_bins * res_bp\n","        if L_bp > eff:\n","            x_base = x_base[..., :eff]\n","        x = F.relu(self.conv1(x_base))\n","        x = F.relu(self.conv2(x))\n","        x = self.proj(x)                    # [B,D,eff]\n","        B,D,L = x.shape\n","        x = x.view(B, D, l_bins, res_bp).mean(dim=-1)  # [B,D,L_bins]\n","        return x.transpose(1,2).contiguous()           # [B,L_bins,D]\n","\n","class EpiEncoder(nn.Module):\n","    def __init__(self, in_dim=2, emb_dim=EPI_EMB_DIM):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(in_dim, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, emb_dim)\n","        )\n","    def forward(self, epi_bins):\n","        B,L,F = epi_bins.shape\n","        return self.net(epi_bins.view(B*L, F)).view(B, L, -1)\n","\n","class FusionHead(nn.Module):\n","    def __init__(self, emb_dim=min(DNA_EMB_DIM, EPI_EMB_DIM)):\n","        super().__init__()\n","        self.fuse = nn.Linear(emb_dim*2, emb_dim)\n","        self.out  = nn.Linear(emb_dim, 1)\n","    def forward(self, dna_emb, epi_emb):\n","        D = min(dna_emb.shape[-1], epi_emb.shape[-1])\n","        if dna_emb.shape[-1] != D: dna_emb = dna_emb[..., :D]\n","        if epi_emb.shape[-1] != D: epi_emb = epi_emb[..., :D]\n","        fused = torch.cat([dna_emb, epi_emb], dim=-1)\n","        fused = F.relu(self.fuse(fused))\n","        return fused, self.out(fused)\n","\n","class ConvTransModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.seq_encoder = SeqEncoder()\n","        self.epi_encoder = EpiEncoder()\n","        self.fusion_head = FusionHead()\n","    def forward(self, x_base4, x_epi, res_bp=RES_BP, l_bins=L_BINS):\n","        dna_emb = self.seq_encoder(x_base4, res_bp, l_bins)  # [B,L,D1]\n","        epi_emb = self.epi_encoder(x_epi)                    # [B,L,D2]\n","        fused, _ = self.fusion_head(dna_emb, epi_emb)\n","        return {\"dna_emb\": dna_emb, \"epi_emb\": epi_emb, \"fused\": fused}\n","\n","def register_hooks(model: nn.Module):\n","    caches = {}\n","    def mk(name):\n","        def _hook(_, __, out):\n","            caches[name] = out.detach()\n","        return _hook\n","    model.seq_encoder.register_forward_hook(mk(\"dna_emb\"))\n","    model.epi_encoder.register_forward_hook(mk(\"epi_emb\"))\n","    return caches\n","\n","# Utility: convert [L,5] (a,t,c,g,n) to [L,4] (A,C,G,T)\n","def onehot5_to_base4(seq_onehot5: np.ndarray) -> np.ndarray:\n","    a = seq_onehot5[:,0:1]\n","    t = seq_onehot5[:,1:2]\n","    c = seq_onehot5[:,2:3]\n","    g = seq_onehot5[:,3:4]\n","    return np.concatenate([a,c,g,t], axis=1).astype(np.float32)  # [L,4]\n","\n","# ================================================================\n","# Main: build dataset, bigWig handles, run model on GPU, save shards\n","# ================================================================\n","def main():\n","    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","    assert os.path.isdir(DNA_DIR), f\"DNA_DIR not found: {DNA_DIR}\"\n","    assert os.path.isdir(HIC_DIR), f\"HIC_DIR not found: {HIC_DIR}\"\n","\n","    # Ensure bigWigs are under the expected folder (copy if needed)\n","    Path(f\"{CELLTYPE_ROOT}/genomic_features\").mkdir(parents=True, exist_ok=True)\n","    for src in [ATAC_BW, CTCF_BW]:\n","        expected = f\"{CELLTYPE_ROOT}/genomic_features/{Path(src).name}\"\n","        if os.path.abspath(src) != os.path.abspath(expected):\n","            if not os.path.exists(expected):\n","                import shutil; shutil.copy2(src, expected)\n","\n","    # Feature dicts just to construct GenomicFeature for length checks\n","    feat_dicts = {\n","        \"ctcf_log2fc\": {\"file_name\": Path(CTCF_BW).name, \"norm\": None},\n","        \"atac\":        {\"file_name\": Path(ATAC_BW).name,  \"norm\": \"log\"},\n","    }\n","\n","    # Use 'val' (chr10) by default; override by CHROMS above\n","    mode = \"val\" if CHROMS is None else \"train\"\n","    ds = GenomeDataset(CELLTYPE_ROOT, ASSEMBLY, feat_dicts, mode=mode, use_aug=False)\n","\n","    # Open bigWigs ONCE, and use nBins for per-bin means\n","    bw_atac = pbw.open(ATAC_BW)\n","    bw_ctcf = pbw.open(CTCF_BW)\n","\n","    # Build model on GPU\n","    model = ConvTransModel().to(device).eval()\n","    if CKPT_PATH and os.path.exists(CKPT_PATH):\n","        sd = torch.load(CKPT_PATH, map_location=\"cpu\")\n","        state = sd.get(\"state_dict\", sd)\n","        model.load_state_dict(state, strict=False)\n","        print(\"Loaded checkpoint:\", CKPT_PATH)\n","    else:\n","        print(\"No checkpoint provided; embeddings will be untrained/random.\")\n","\n","    caches = register_hooks(model)\n","\n","    shard_rows = []\n","    shard_id = 0\n","    def flush_shard():\n","        nonlocal shard_rows, shard_id\n","        if not shard_rows: return\n","        df = pd.DataFrame(shard_rows)\n","        out_path = os.path.join(OUT_DIR, f\"embeddings_{shard_id:05d}.parquet\")\n","        df.to_parquet(out_path, index=False)\n","        print(f\"Wrote {out_path} ({len(df)} rows)\")\n","        shard_id += 1\n","        shard_rows = []\n","\n","    # Iterate samples (windows)\n","    total = len(ds)\n","    print(f\"Total windows in dataset: {total}\")\n","    max_n = total if (MAX_SAMPLES is None) else min(MAX_SAMPLES, total)\n","\n","    for idx in range(max_n):\n","        seq5, _features_placeholder, _mat256, win_start, win_end, chr_name, _local = ds[idx]\n","\n","        # ----- Build inputs -----\n","        # DNA to base4 [1,4,L_bp] on GPU\n","        base4 = onehot5_to_base4(seq5)                              # [L_bp,4]\n","        x_base = torch.from_numpy(base4.T).unsqueeze(0).to(device)  # [1,4,L_bp]\n","\n","        # Epi via nBins: directly get per-bin means from bigWig (FAST)\n","        atac_bins = bw_atac.stats(chr_name, int(win_start), int(win_end), nBins=L_BINS, type=\"mean\")\n","        ctcf_bins = bw_ctcf.stats(chr_name, int(win_start), int(win_end), nBins=L_BINS, type=\"mean\")\n","        atac_bins = np.log1p(np.nan_to_num(np.array(atac_bins, dtype=np.float32), 0.0))\n","        ctcf_bins = np.nan_to_num(np.array(ctcf_bins, dtype=np.float32), 0.0)\n","        epi_bins  = np.stack([atac_bins, ctcf_bins], axis=-1)       # [L_BINS,2]\n","        x_epi = torch.from_numpy(epi_bins).unsqueeze(0).to(device)  # [1,L_BINS,2]\n","\n","        # ----- Forward on GPU (hooks will capture) -----\n","        with torch.no_grad():\n","            _ = model(x_base, x_epi, RES_BP, L_BINS)\n","\n","        # Pull from caches (CPU numpy)\n","        dna_emb = caches[\"dna_emb\"].detach().cpu().numpy()[0]  # [L_BINS, D1]\n","        epi_emb = caches[\"epi_emb\"].detach().cpu().numpy()[0]  # [L_BINS, D2]\n","\n","        # Save rows\n","        for l in range(L_BINS):\n","            bin_start = int(win_start + l*RES_BP)\n","            bin_end   = bin_start + RES_BP\n","            shard_rows.append({\n","                \"assembly\": ASSEMBLY,\n","                \"celltype\": CELLTYPE,\n","                \"chr\": chr_name,\n","                \"win_start\": int(win_start),\n","                \"win_end\": int(win_end),\n","                \"bin_idx\": int(l),\n","                \"bin_start\": bin_start,\n","                \"bin_end\": bin_end,\n","                \"dna_emb\": dna_emb[l].astype(np.float32).tolist(),\n","                \"epi_emb\": epi_emb[l].astype(np.float32).tolist()\n","            })\n","\n","        if len(shard_rows) >= ROWS_PER_SHARD:\n","            flush_shard()\n","\n","        if (idx+1) % 50 == 0 or (idx+1) == max_n:\n","            print(f\"Processed {idx+1}/{max_n} windows\")\n","\n","    flush_shard()\n","\n","    # Close bigWigs\n","    bw_atac.close()\n","    bw_ctcf.close()\n","    torch.cuda.empty_cache()\n","    print(\"Done.\")\n","\n","# Run\n","main()\n"],"metadata":{"id":"IAvxYu2O7ZAN","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"error","timestamp":1762984170035,"user_tz":300,"elapsed":13007,"user":{"displayName":"Sneha Bapana","userId":"06343812349805612711"}},"outputId":"e285758d-97e1-4851-c649-0461bcfd09a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Using assembly: hg38\n","Feature path: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/genomic_features/ctcf_log2fc.bw\n","Normalization status: None\n","Feature path: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/genomic_features/atac.bw\n","Normalization status: log\n","Loading chromosome datasets…\n","Loading chromosome chr10…\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr10.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr10.npz\n","Chromosome datasets loaded.\n","No checkpoint provided; embeddings will be untrained/random.\n","Total windows in dataset: 198\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3285834697.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;31m# Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-3285834697.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# ----- Build inputs -----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# DNA to base4 [1,4,L_bp] on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbase4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot5_to_base4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq5\u001b[0m\u001b[0;34m)\u001b[0m                              \u001b[0;31m# [L_bp,4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0mx_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [1,4,L_bp]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3285834697.py\u001b[0m in \u001b[0;36monehot5_to_base4\u001b[0;34m(seq_onehot5)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_onehot5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_onehot5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [L,4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# ================================================================\n","# Colab GPU-ready, fast nBins version (C.Origami-aligned)\n","# - 8,192 bp bins (L_BINS = 256) over 2,097,152 bp windows\n","# - Uses GPU for the model\n","# - Robust bigWig nBins stats (handles None, chr mismatches)\n","# - Has MAX_SAMPLES guard\n","# - Saves per-bin DNA & Epi embeddings to Parquet shards\n","# ================================================================\n","\n","# ---------- Colab installs ----------\n","!pip -q install pyBigWig pyarrow\n","\n","# ---------- CONFIG ----------\n","from pathlib import Path\n","\n","# Folder layout expected:\n","#   {CELLTYPE_ROOT}/genomic_features/atac.bw\n","#   {CELLTYPE_ROOT}/genomic_features/ctcf_log2fc.bw\n","#   {CELLTYPE_ROOT}/hic_matrix/chr1.npz, chr2.npz, ...\n","#   {CELLTYPE_ROOT}/../dna_sequence/chr1.fa.gz, chr2.fa.gz, ...\n","#   {CELLTYPE_ROOT}/../centrotelo.bed   (optional)\n","CELLTYPE_ROOT = \"/content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90\"      # <-- EDIT\n","ASSEMBLY      = \"hg38\"\n","CELLTYPE      = \"IMR90\"\n","\n","ATAC_BW       = f\"{CELLTYPE_ROOT}/genomic_features/atac.bw\"\n","CTCF_BW       = f\"{CELLTYPE_ROOT}/genomic_features/ctcf_log2fc.bw\"\n","DNA_DIR       = f\"{CELLTYPE_ROOT}/../dna_sequence\"\n","HIC_DIR       = f\"{CELLTYPE_ROOT}/hic_matrix\"\n","CENTROTELO_BED= f\"{CELLTYPE_ROOT}/../centrotelo.bed\"   # set to None if you don't have it\n","\n","OUT_DIR       = \"/content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out\"  # Parquet outputs\n","\n","# Window/bin params (C.Origami-aligned)\n","RES_BP        = 10000                 # 8,192 bp per bin\n","WINDOW_BP     = 2_097_152            # 2^21 bp window\n","L_BINS        = int(WINDOW_BP // RES_BP)  # 256 bins\n","SAMPLE_BINS   = 500                  # 5 Mb proposed frame\n","STRIDE_BINS   = 61                   # ~500 kb step (≈ 61 * 8,192)\n","\n","# Limit how many samples to process (set None to run all)\n","MAX_SAMPLES   = 300                  # <-- change to None for full run\n","\n","# Choose chromosomes (None -> default split; for quick test use [\"chr10\"])\n","CHROMS        = [\"chr10\"]            # <-- edit or set to None\n","\n","# Output sharding\n","ROWS_PER_SHARD= 10_000\n","\n","# Model dimensions\n","DNA_EMB_DIM   = 128\n","EPI_EMB_DIM   = 128\n","\n","# Optional checkpoint (for this simple model). Leave None for random weights.\n","CKPT_PATH     = None\n","\n","# ================================================================\n","# Imports & GPU setup\n","# ================================================================\n","import os, io, gzip, math, random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pyBigWig as pbw\n","\n","from typing import List, Tuple\n","\n","# Ensure GPU\n","assert torch.cuda.is_available(), \"No GPU detected. In Colab: Runtime > Change runtime type > Hardware accelerator: GPU\"\n","device = torch.device(\"cuda\")\n","torch.backends.cudnn.benchmark = True\n","print(\"Using device:\", device)\n","\n","# ================================================================\n","# Feature I/O helpers (self-contained)\n","# ================================================================\n","class Feature():\n","    def __init__(self, **kwargs):\n","        self.load(**kwargs)\n","    def load(self, **kwargs): raise NotImplementedError\n","    def get(self, *args, **kwargs): raise NotImplementedError\n","    def __len__(self): raise NotImplementedError\n","\n","class HiCFeature(Feature):\n","    def load(self, path=None):\n","        self.hic = self._load_npz(path)\n","    def get(self, start, window=WINDOW_BP, res=RES_BP):\n","        start_bin = int(start / res)\n","        range_bin = int(window / res)\n","        end_bin   = start_bin + range_bin\n","        return self._diag_to_mat(self.hic, start_bin, end_bin)\n","    def _load_npz(self, path):\n","        print(f\"Reading Hi-C: {path}\")\n","        return dict(np.load(path))\n","    def _diag_to_mat(self, ori_load, start, end):\n","        square_len = end - start\n","        diag_load = {}\n","        for diag_i in range(square_len):\n","            # Be tolerant if some diagonals are missing: pad with zeros\n","            pos_key = str(diag_i); neg_key = str(-diag_i)\n","            pos_arr = ori_load.get(pos_key, None)\n","            neg_arr = ori_load.get(neg_key, None)\n","            max_len = square_len - diag_i\n","            if pos_arr is None:\n","                diag_load[pos_key] = np.zeros(max_len, dtype=np.float32)\n","            else:\n","                diag_load[pos_key] = pos_arr[start : start + max_len]\n","            if neg_arr is None:\n","                diag_load[neg_key] = np.zeros(max_len, dtype=np.float32)\n","            else:\n","                diag_load[neg_key] = neg_arr[start : start + max_len]\n","\n","        diag_region = []\n","        for diag_i in range(square_len):\n","            row = []\n","            for line_i in range(-diag_i, -diag_i + square_len):\n","                if line_i < 0:\n","                    row.append(diag_load[str(line_i)][line_i + diag_i])\n","                else:\n","                    row.append(diag_load[str(line_i)][diag_i])\n","            diag_region.append(row)\n","        return np.array(diag_region, dtype=np.float32).reshape(square_len, square_len)\n","    def __len__(self):\n","        return len(self.hic['0'])\n","\n","class GenomicFeature(Feature):\n","    # We won't fetch per-base values here; nBins is used downstream for speed.\n","    def __init__(self, path, norm):\n","        self.path = path\n","        self.norm = norm\n","        print(f\"Feature path: {path}\\nNormalization status: {norm}\")\n","    def load(self, **kwargs): pass\n","    def get(self, *args, **kwargs): raise NotImplementedError(\"Use bigWig nBins path in main loop\")\n","    def length(self, chr_name):\n","        with pbw.open(self.path) as bw:\n","            return bw.chroms(chr_name)\n","\n","class SequenceFeature(Feature):\n","    def load(self, path=None):\n","        self.seq = self._read_seq(path)\n","    def get(self, start, end):\n","        seq = self._slice(self.seq, start, end)\n","        return self._onehot(seq)\n","    def __len__(self):\n","        return len(self.seq)\n","    def _read_seq(self, dna_path):\n","        print(f\"Reading sequence: {dna_path}\")\n","        with gzip.open(dna_path, \"r\") as f:\n","            raw = f.read().decode(\"utf-8\")\n","        raw = raw[raw.find('\\n')+1:].replace('\\n','').lower()\n","        return raw\n","    def _slice(self, seq, start, end):\n","        return seq[start:end]\n","    def _onehot(self, seq):\n","        # [a,t,c,g,n] ordering\n","        enc = {'a':0,'t':1,'c':2,'g':3,'n':4}\n","        idx = np.fromiter((enc.get(ch,4) for ch in seq), dtype=np.int32, count=len(seq))\n","        out = np.zeros((len(seq), 5), dtype=np.float32)\n","        out[np.arange(len(seq)), idx] = 1.0\n","        return out\n","\n","# ================================================================\n","# Datasets\n","# ================================================================\n","class ChromosomeDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    Provides (sequence, features[], Hi-C) windows across a chromosome.\n","    Features[] are placeholders here; we'll fetch ATAC/CTCF via nBins in main.\n","    \"\"\"\n","    def __init__(self, celltype_root, chr_name, omit_regions, feature_list, use_aug=True):\n","        self.use_aug      = use_aug\n","        self.res          = RES_BP\n","        self.bins_float   = WINDOW_BP / self.res   # 256.0\n","        self.sample_bins  = SAMPLE_BINS\n","        self.stride       = STRIDE_BINS\n","        self.chr_name     = chr_name\n","\n","        print(f\"Loading chromosome {chr_name}…\")\n","        dna_path = f\"{celltype_root}/../dna_sequence/{chr_name}.fa.gz\"\n","        hic_path = f\"{celltype_root}/hic_matrix/{chr_name}.npz\"\n","        self.seq = SequenceFeature(path=dna_path)\n","        self.mat = HiCFeature(path=hic_path)\n","        self.genomic_features = feature_list  # used for length checks\n","\n","        self.omit_regions = omit_regions if omit_regions is not None else np.zeros((0,2), dtype=int)\n","        self._check_lengths()\n","        self.all_intervals = self._get_active_intervals()\n","        self.intervals     = self._filter(self.all_intervals, self.omit_regions)\n","\n","    def __len__(self): return len(self.intervals)\n","\n","    def __getitem__(self, idx):\n","        start, end = self.intervals[idx]\n","        target_size = int(self.bins_float * self.res)  # 256 * 8192 = 2,097,152 bp\n","\n","        if self.use_aug:\n","            start, end = self._shift_aug(target_size, start, end)\n","        else:\n","            start, end = self._shift_fix(target_size, start, end)\n","\n","        # DNA one-hot [L_bp,5]\n","        seq = self.seq.get(start, end)\n","\n","        # Hi-C region (already 256x256 with RES_BP=8192 and L_BINS=256)\n","        mat = self.mat.get(start, window=WINDOW_BP, res=self.res).astype(np.float32)\n","        mat = np.log1p(mat)  # no resize needed\n","\n","        # Optional light aug on sequence + mat\n","        if self.use_aug:\n","            seq = seq + np.random.randn(*seq.shape).astype(np.float32) * 0.1\n","            if np.random.rand() < 0.5:\n","                seq = np.flip(seq, 0).copy()\n","                if np.random.rand() < 0.5:\n","                    a,t,c,g,n = seq[:,0:1], seq[:,1:2], seq[:,2:3], seq[:,3:4], seq[:,4:5]\n","                    seq = np.concatenate([t,a,g,c,n], axis=1)\n","                mat = np.flip(mat, (0,1)).copy()\n","\n","        # features[] placeholder kept for API compatibility\n","        features_placeholder = []\n","        return seq, features_placeholder, mat, start, end\n","\n","    # helpers\n","    def _get_active_intervals(self):\n","        chr_bins = len(self.seq) / self.res\n","        data_size = int((chr_bins - self.sample_bins) / self.stride)\n","        data_size = max(0, data_size)\n","        starts = (np.arange(data_size).reshape(-1,1) * self.stride)\n","        intervals_bin = np.concatenate([starts, starts + self.sample_bins], axis=1) if data_size>0 else np.zeros((0,2), dtype=int)\n","        return (intervals_bin * self.res).astype(int)\n","    def _filter(self, intervals, omit_regions):\n","        if omit_regions is None or len(omit_regions)==0:\n","            return intervals.tolist()\n","        valid = []\n","        for start, end in intervals:\n","            start_cond = start <= omit_regions[:,1]\n","            end_cond   = omit_regions[:,0] <= end\n","            if int(np.sum(start_cond * end_cond)) == 0:\n","                valid.append([int(start), int(end)])\n","        return valid\n","    def _shift_aug(self, target_size, start, end):\n","        max_off = max(1, (end - start - target_size))\n","        offset = random.randrange(max_off)\n","        return start + offset, start + offset + target_size\n","    def _shift_fix(self, target_size, start, end):\n","        return start, start + target_size\n","    def _check_lengths(self):\n","        if len(self.genomic_features) > 0:\n","            f0_len = self.genomic_features[0].length(self.chr_name)\n","            assert len(self.seq) == f0_len, f\"Sequence {len(self.seq)} vs first feature {f0_len} mismatch.\"\n","        dna_bins = len(self.seq) / self.res\n","        hic_bins = len(self.mat)\n","        assert abs(dna_bins - hic_bins) < 2, f\"DNA bins {dna_bins} vs Hi-C bins {hic_bins} mismatch.\"\n","\n","class GenomeDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    Default split:\n","      train -> autosomes except chr10/chr15 and excluding chrX\n","      val   -> chr10\n","      test  -> chr15\n","    \"\"\"\n","    def __init__(self, celltype_root, assembly, feat_dicts, mode=\"val\", use_aug=False):\n","        self.data_root = celltype_root\n","        self.use_aug   = use_aug if mode==\"train\" else False\n","\n","        self.chr_names = self._enumerate_chrs(assembly)\n","        if mode == \"train\":\n","            for drop in [\"chr10\",\"chr15\",\"chrX\"]:\n","                if drop in self.chr_names:\n","                    self.chr_names.remove(drop)\n","        elif mode == \"val\":\n","            self.chr_names = [\"chr10\"]\n","        elif mode == \"test\":\n","            self.chr_names = [\"chr15\"]\n","        else:\n","            raise ValueError(f\"Unknown mode: {mode}\")\n","\n","        # Override with manual CHROMS if provided\n","        global CHROMS\n","        if CHROMS is not None:\n","            self.chr_names = CHROMS\n","\n","        # Feature objects (for length checks; values fetched via nBins later)\n","        self.genomic_features = []\n","        for d in feat_dicts.values():\n","            self.genomic_features.append(GenomicFeature(f\"{celltype_root}/genomic_features/{Path(d['file_name']).name}\", d['norm']))\n","\n","        # Omit regions\n","        if CENTROTELO_BED and os.path.exists(CENTROTELO_BED):\n","            omit_dict = self._proc_bed(CENTROTELO_BED)\n","        else:\n","            print(\"No centrotelo bed provided; proceeding without region masking.\")\n","            omit_dict = {name: np.zeros((0,2), dtype=int) for name in self.chr_names}\n","\n","        print(\"Loading chromosome datasets…\")\n","        self.chr_data, self.lengths = {}, []\n","        for chr_name in self.chr_names:\n","            ds = ChromosomeDataset(self.data_root, chr_name, omit_dict.get(chr_name, None),\n","                                   self.genomic_features, use_aug=self.use_aug)\n","            self.chr_data[chr_name] = ds\n","            self.lengths.append(len(ds))\n","        print(\"Chromosome datasets loaded.\")\n","        self.ranges = self._ranges(self.lengths)\n","\n","    def __len__(self): return sum(self.lengths)\n","    def __getitem__(self, idx):\n","        chr_name, local_idx = self._locate(idx)\n","        seq, features_placeholder, mat, start, end = self.chr_data[chr_name][local_idx]\n","        return seq, features_placeholder, mat, start, end, chr_name, local_idx\n","\n","    # helpers\n","    def _enumerate_chrs(self, assembly):\n","        print(f\"Using assembly: {assembly}\")\n","        if assembly in [\"hg38\",\"hg19\"]:\n","            nums = list(range(1,23))\n","        elif assembly in [\"mm10\",\"mm9\"]:\n","            nums = list(range(1,20))\n","        else:\n","            raise ValueError(f\"Assembly {assembly} unknown.\")\n","        return [f\"chr{n}\" for n in nums] + [\"chrX\"]\n","    def _ranges(self, lengths):\n","        cur, out = 0, []\n","        for L in lengths:\n","            out.append([cur, cur + L - 1])\n","            cur += L\n","        return out\n","    def _locate(self, idx):\n","        for i, (s,e) in enumerate(self.ranges):\n","            if s <= idx <= e:\n","                return self.chr_names[i], idx - s\n","        raise IndexError(idx)\n","    def _proc_bed(self, bed_path):\n","        df = pd.read_csv(bed_path, sep=\"\\t\", names=[\"chr\",\"start\",\"end\"])\n","        return {k: v[[\"start\",\"end\"]].to_numpy(dtype=int) for k,v in df.groupby(\"chr\")}\n","\n","# ================================================================\n","# Model (dual encoders) + hooks\n","# ================================================================\n","class SeqEncoder(nn.Module):\n","    def __init__(self, in_channels=4, emb_dim=DNA_EMB_DIM):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=15, padding=7)\n","        self.conv2 = nn.Conv1d(64, 128, kernel_size=7, padding=3)\n","        self.proj  = nn.Conv1d(128, emb_dim, kernel_size=1)\n","    def forward(self, x_base, res_bp=RES_BP, l_bins=L_BINS):\n","        # x_base: [B,4,L_bp] -> trim to integer number of bins\n","        L_bp = x_base.shape[-1]\n","        eff  = l_bins * res_bp\n","        if L_bp > eff:\n","            x_base = x_base[..., :eff]\n","        x = F.relu(self.conv1(x_base))\n","        x = F.relu(self.conv2(x))\n","        x = self.proj(x)                    # [B,D,eff]\n","        B,D,L = x.shape\n","        x = x.view(B, D, l_bins, res_bp).mean(dim=-1)  # [B,D,L_bins]\n","        return x.transpose(1,2).contiguous()           # [B,L_bins,D]\n","\n","class EpiEncoder(nn.Module):\n","    def __init__(self, in_dim=2, emb_dim=EPI_EMB_DIM):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(in_dim, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, emb_dim)\n","        )\n","    def forward(self, epi_bins):\n","        B,L,F = epi_bins.shape\n","        return self.net(epi_bins.view(B*L, F)).view(B, L, -1)\n","\n","class FusionHead(nn.Module):\n","    def __init__(self, emb_dim=min(DNA_EMB_DIM, EPI_EMB_DIM)):\n","        super().__init__()\n","        self.fuse = nn.Linear(emb_dim*2, emb_dim)\n","        self.out  = nn.Linear(emb_dim, 1)\n","    def forward(self, dna_emb, epi_emb):\n","        D = min(dna_emb.shape[-1], epi_emb.shape[-1])\n","        if dna_emb.shape[-1] != D: dna_emb = dna_emb[..., :D]\n","        if epi_emb.shape[-1] != D: epi_emb = epi_emb[..., :D]\n","        fused = torch.cat([dna_emb, epi_emb], dim=-1)\n","        fused = F.relu(self.fuse(fused))\n","        return fused, self.out(fused)\n","\n","class ConvTransModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.seq_encoder = SeqEncoder()\n","        self.epi_encoder = EpiEncoder()\n","        self.fusion_head = FusionHead()\n","    def forward(self, x_base4, x_epi, res_bp=RES_BP, l_bins=L_BINS):\n","        dna_emb = self.seq_encoder(x_base4, res_bp, l_bins)  # [B,L,D1]\n","        epi_emb = self.epi_encoder(x_epi)                    # [B,L,D2]\n","        fused, _ = self.fusion_head(dna_emb, epi_emb)\n","        return {\"dna_emb\": dna_emb, \"epi_emb\": epi_emb, \"fused\": fused}\n","\n","def register_hooks(model: nn.Module):\n","    caches = {}\n","    def mk(name):\n","        def _hook(_, __, out):\n","            caches[name] = out.detach()\n","        return _hook\n","    model.seq_encoder.register_forward_hook(mk(\"dna_emb\"))\n","    model.epi_encoder.register_forward_hook(mk(\"epi_emb\"))\n","    return caches\n","\n","# Utility: convert [L,5] (a,t,c,g,n) to [L,4] (A,C,G,T)\n","def onehot5_to_base4(seq_onehot5: np.ndarray) -> np.ndarray:\n","    a = seq_onehot5[:,0:1]\n","    t = seq_onehot5[:,1:2]\n","    c = seq_onehot5[:,2:3]\n","    g = seq_onehot5[:,3:4]\n","    return np.concatenate([a,c,g,t], axis=1).astype(np.float32)  # [L,4]\n","\n","# ================================================================\n","# Main: build dataset, bigWig handles, run model on GPU, save shards\n","# ================================================================\n","def main():\n","    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","    assert os.path.isdir(DNA_DIR), f\"DNA_DIR not found: {DNA_DIR}\"\n","    assert os.path.isdir(HIC_DIR), f\"HIC_DIR not found: {HIC_DIR}\"\n","\n","    # Ensure bigWigs are under the expected folder (copy if needed)\n","    Path(f\"{CELLTYPE_ROOT}/genomic_features\").mkdir(parents=True, exist_ok=True)\n","    for src in [ATAC_BW, CTCF_BW]:\n","        expected = f\"{CELLTYPE_ROOT}/genomic_features/{Path(src).name}\"\n","        if os.path.abspath(src) != os.path.abspath(expected):\n","            if not os.path.exists(expected):\n","                import shutil; shutil.copy2(src, expected)\n","\n","    # Feature dicts just to construct GenomicFeature for length checks\n","    feat_dicts = {\n","        \"ctcf_log2fc\": {\"file_name\": Path(CTCF_BW).name, \"norm\": None},\n","        \"atac\":        {\"file_name\": Path(ATAC_BW).name,  \"norm\": \"log\"},\n","    }\n","\n","    # Use 'val' (chr10) by default; override by CHROMS above\n","    mode = \"val\" if CHROMS is None else \"train\"\n","    ds = GenomeDataset(CELLTYPE_ROOT, ASSEMBLY, feat_dicts, mode=mode, use_aug=False)\n","\n","    # Open bigWigs ONCE, and use nBins for per-bin means\n","    bw_atac = pbw.open(ATAC_BW)\n","    bw_ctcf = pbw.open(CTCF_BW)\n","\n","    # Build model on GPU\n","    model = ConvTransModel().to(device).eval()\n","    if CKPT_PATH and os.path.exists(CKPT_PATH):\n","        sd = torch.load(CKPT_PATH, map_location=\"cpu\")\n","        state = sd.get(\"state_dict\", sd)\n","        model.load_state_dict(state, strict=False)\n","        print(\"Loaded checkpoint:\", CKPT_PATH)\n","    else:\n","        print(\"No checkpoint provided; embeddings will be untrained/random.\")\n","\n","    caches = register_hooks(model)\n","\n","    shard_rows = []\n","    shard_id = 0\n","    def flush_shard():\n","        nonlocal shard_rows, shard_id\n","        if not shard_rows: return\n","        df = pd.DataFrame(shard_rows)\n","        out_path = os.path.join(OUT_DIR, f\"embeddings2_{shard_id:05d}.parquet\")\n","        df.to_parquet(out_path, index=False)\n","        print(f\"Wrote {out_path} ({len(df)} rows)\")\n","        shard_id += 1\n","        shard_rows = []\n","\n","    # Iterate samples (windows)\n","    total = len(ds)\n","    print(f\"Total windows in dataset: {total}\")\n","    max_n = total if (MAX_SAMPLES is None) else min(MAX_SAMPLES, total)\n","\n","    for idx in range(max_n):\n","        seq5, _features_placeholder, _mat256, win_start, win_end, chr_name, _local = ds[idx]\n","\n","        # ----- Build inputs -----\n","        # DNA to base4 [1,4,L_bp] on GPU\n","        base4 = onehot5_to_base4(seq5)                              # [L_bp,4]\n","        x_base = torch.from_numpy(base4.T).unsqueeze(0).to(device)  # [1,4,L_bp]\n","\n","        # ----- Epi via nBins: robust handling for None and chr mismatches -----\n","        try:\n","            atac_list = bw_atac.stats(chr_name, int(win_start), int(win_end), nBins=L_BINS, type=\"mean\")\n","            ctcf_list = bw_ctcf.stats(chr_name, int(win_start), int(win_end), nBins=L_BINS, type=\"mean\")\n","        except RuntimeError as e:\n","            avail_atac = list(bw_atac.chroms().keys())\n","            avail_ctcf = list(bw_ctcf.chroms().keys())\n","            raise RuntimeError(\n","                f\"bigWig stats failed for chromosome {chr_name}. \"\n","                f\"ATAC first chroms: {avail_atac[:10]} ... \"\n","                f\"CTCF first chroms: {avail_ctcf[:10]} ... \"\n","                f\"Original error: {e}\"\n","            )\n","\n","        atac_bins = np.array([0.0 if v is None else float(v) for v in atac_list], dtype=np.float32)\n","        ctcf_bins = np.array([0.0 if v is None else float(v) for v in ctcf_list], dtype=np.float32)\n","\n","        if atac_bins.size != L_BINS or ctcf_bins.size != L_BINS:\n","            raise ValueError(\n","                f\"Expected {L_BINS} bins but got ATAC={atac_bins.size}, CTCF={ctcf_bins.size}. \"\n","                f\"win: {chr_name}:{win_start}-{win_end}\"\n","            )\n","\n","        atac_bins = np.log1p(atac_bins)  # paper-consistent\n","        epi_bins  = np.stack([atac_bins, ctcf_bins], axis=-1).astype(np.float32)  # [L_BINS, 2]\n","        x_epi     = torch.from_numpy(epi_bins).unsqueeze(0).to(device)            # [1,L_BINS,2]\n","\n","        # ----- Forward on GPU (hooks will capture) -----\n","        with torch.no_grad():\n","            _ = model(x_base, x_epi, RES_BP, L_BINS)\n","\n","        # Pull from caches (CPU numpy)\n","        dna_emb = caches[\"dna_emb\"].detach().cpu().numpy()[0]  # [L_BINS, D1]\n","        epi_emb = caches[\"epi_emb\"].detach().cpu().numpy()[0]  # [L_BINS, D2]\n","\n","        # Save rows\n","        for l in range(L_BINS):\n","            bin_start = int(win_start + l*RES_BP)\n","            bin_end   = bin_start + RES_BP\n","            shard_rows.append({\n","                \"assembly\": ASSEMBLY,\n","                \"celltype\": CELLTYPE,\n","                \"chr\": chr_name,\n","                \"win_start\": int(win_start),\n","                \"win_end\": int(win_end),\n","                \"bin_idx\": int(l),\n","                \"bin_start\": bin_start,\n","                \"bin_end\": bin_end,\n","                \"dna_emb\": dna_emb[l].astype(np.float32).tolist(),\n","                \"epi_emb\": epi_emb[l].astype(np.float32).tolist()\n","            })\n","\n","        if len(shard_rows) >= ROWS_PER_SHARD:\n","            flush_shard()\n","\n","        if (idx+1) % 50 == 0 or (idx+1) == max_n:\n","            print(f\"Processed {idx+1}/{max_n} windows\")\n","\n","    flush_shard()\n","\n","    # Close bigWigs\n","    bw_atac.close()\n","    bw_ctcf.close()\n","    torch.cuda.empty_cache()\n","    print(\"Done.\")\n","\n","# Run\n","main()\n"],"metadata":{"id":"bdUnffjS_bnZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762984281644,"user_tz":300,"elapsed":106792,"user":{"displayName":"Sneha Bapana","userId":"06343812349805612711"}},"outputId":"ef8539a4-9f97-4087-bdd2-55ee4b4c60e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Using assembly: hg38\n","Feature path: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/genomic_features/ctcf_log2fc.bw\n","Normalization status: None\n","Feature path: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/genomic_features/atac.bw\n","Normalization status: log\n","Loading chromosome datasets…\n","Loading chromosome chr10…\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr10.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr10.npz\n","Chromosome datasets loaded.\n","No checkpoint provided; embeddings will be untrained/random.\n","Total windows in dataset: 198\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings2_00000.parquet (10032 rows)\n","Processed 50/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings2_00001.parquet (10032 rows)\n","Processed 100/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings2_00002.parquet (10032 rows)\n","Processed 150/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings2_00003.parquet (10032 rows)\n","Processed 198/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings2_00004.parquet (1254 rows)\n","Done.\n"]}]},{"cell_type":"code","source":["# ================================================================\n","# Colab GPU-ready, nBins version (per-chrom processing, chr in filenames)\n","# - 10 kb bins, 2,097,152 bp windows (L_BINS=209)\n","# - Iterates chr1..chr22, chrX, chrY\n","# - Writes shards like embeddings_chr10_00003.parquet\n","# ================================================================\n","\n","# ---------- Colab installs ----------\n","!pip -q install pyBigWig pyarrow scikit-image\n","\n","# ---------- CONFIG ----------\n","from pathlib import Path\n","\n","CELLTYPE_ROOT = \"/content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90\"\n","ASSEMBLY      = \"hg38\"\n","CELLTYPE      = \"IMR90\"\n","\n","ATAC_BW       = f\"{CELLTYPE_ROOT}/genomic_features/atac.bw\"\n","CTCF_BW       = f\"{CELLTYPE_ROOT}/genomic_features/ctcf_log2fc.bw\"\n","DNA_DIR       = f\"{CELLTYPE_ROOT}/../dna_sequence\"\n","HIC_DIR       = f\"{CELLTYPE_ROOT}/hic_matrix\"\n","CENTROTELO_BED= f\"{CELLTYPE_ROOT}/../centrotelo.bed\"   # or None\n","\n","OUT_DIR       = \"/content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out\"\n","\n","# Window/bin params (10kb data)\n","RES_BP        = 10_000\n","WINDOW_BP     = 2_097_152\n","L_BINS        = int(WINDOW_BP // RES_BP)   # 209\n","SAMPLE_BINS   = 500\n","STRIDE_BINS   = 61\n","IMAGE_SCALE   = 256\n","\n","MAX_WINDOWS_PER_CHR = None      # set to small int for quick smoke tests\n","ROWS_PER_SHARD      = 10_000\n","\n","DNA_EMB_DIM   = 128\n","EPI_EMB_DIM   = 128\n","CKPT_PATH     = None\n","\n","# ================================================================\n","# Imports & GPU setup\n","# ================================================================\n","import os, io, gzip, math, random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pyBigWig as pbw\n","from skimage.transform import resize\n","\n","assert torch.cuda.is_available(), \"Enable GPU: Runtime > Change runtime type > GPU\"\n","device = torch.device(\"cuda\")\n","torch.backends.cudnn.benchmark = True\n","print(\"Using device:\", device)\n","\n","# ================================================================\n","# Feature I/O helpers\n","# ================================================================\n","class Feature():\n","    def __init__(self, **kwargs): self.load(**kwargs)\n","    def load(self, **kwargs): raise NotImplementedError\n","    def get(self, *args, **kwargs): raise NotImplementedError\n","    def __len__(self): raise NotImplementedError\n","\n","class HiCFeature(Feature):\n","    def load(self, path=None):\n","        print(f\"Reading Hi-C: {path}\")\n","        self.hic = dict(np.load(path))\n","    def get(self, start, window=WINDOW_BP, res=RES_BP):\n","        start_bin = int(start / res)\n","        end_bin   = start_bin + int(window / res)\n","        return self._diag_to_mat(self.hic, start_bin, end_bin)\n","    def _diag_to_mat(self, ori_load, start, end):\n","        square_len = end - start\n","        diag_load = {}\n","        for d in range(square_len):\n","            diag_load[str(d)]  = ori_load[str(d)][start : start + (square_len - d)]\n","            diag_load[str(-d)] = ori_load[str(-d)][start : start + (square_len - d)]\n","        rows = []\n","        for d in range(square_len):\n","            row = []\n","            for line in range(-d, -d + square_len):\n","                if line < 0:\n","                    row.append(diag_load[str(line)][line + d])\n","                else:\n","                    row.append(diag_load[str(line)][d])\n","            rows.append(row)\n","        return np.array(rows, dtype=np.float32)\n","    def __len__(self): return len(self.hic['0'])\n","\n","class GenomicFeature(Feature):\n","    def __init__(self, path, norm):\n","        self.path = path\n","        self.norm = norm\n","        print(f\"Feature path: {path}\\nNormalization status: {norm}\")\n","    def load(self, **kwargs): pass\n","    def get(self, *args, **kwargs): raise NotImplementedError\n","    def length(self, chr_name):\n","        with pbw.open(self.path) as bw:\n","            return bw.chroms(chr_name)\n","\n","class SequenceFeature(Feature):\n","    def load(self, path=None):\n","        print(f\"Reading sequence: {path}\")\n","        with gzip.open(path, \"r\") as f:\n","            raw = f.read().decode(\"utf-8\")\n","        raw = raw[raw.find('\\n')+1:].replace('\\n','').lower()\n","        self.seq = raw\n","    def get(self, start, end):\n","        seq = self.seq[start:end]\n","        # onehot [a,t,c,g,n] -> (n,5)\n","        enc = {'a':0,'t':1,'c':2,'g':3,'n':4}\n","        idx = np.fromiter((enc.get(ch,4) for ch in seq), dtype=np.int32, count=len(seq))\n","        out = np.zeros((len(seq), 5), dtype=np.float32)\n","        if len(seq) > 0:\n","            out[np.arange(len(seq)), idx] = 1.0\n","        return out\n","    def __len__(self): return len(self.seq)\n","\n","# ================================================================\n","# Datasets (now we'll build per chromosome explicitly)\n","# ================================================================\n","class ChromosomeDataset(torch.utils.data.Dataset):\n","    def __init__(self, celltype_root, chr_name, omit_regions, feature_list, res_bp=RES_BP):\n","        self.res        = res_bp\n","        self.sample_bins= SAMPLE_BINS\n","        self.stride     = STRIDE_BINS\n","        self.chr_name   = chr_name\n","\n","        dna_path = f\"{celltype_root}/../dna_sequence/{chr_name}.fa.gz\"\n","        hic_path = f\"{celltype_root}/hic_matrix/{chr_name}.npz\"\n","        self.seq = SequenceFeature(path=dna_path)\n","        self.mat = HiCFeature(path=hic_path)\n","        self.genomic_features = feature_list\n","\n","        self.omit_regions = omit_regions if omit_regions is not None else np.zeros((0,2), dtype=int)\n","        self._check_lengths()\n","        self.all_intervals = self._windows()\n","        self.intervals     = self._mask(self.all_intervals, self.omit_regions)\n","\n","    def __len__(self): return len(self.intervals)\n","    def __getitem__(self, idx):\n","        start, end = self.intervals[idx]\n","        seq = self.seq.get(start, end)\n","        mat = self.mat.get(start, window=WINDOW_BP, res=self.res)\n","        mat = np.log1p(resize(mat, (IMAGE_SCALE, IMAGE_SCALE), anti_aliasing=True).astype(np.float32))\n","        return seq, [], mat, start, end\n","\n","    def _windows(self):\n","        chr_bins = len(self.seq) / self.res\n","        n = max(0, int((chr_bins - self.sample_bins) / self.stride))\n","        starts = (np.arange(n).reshape(-1,1) * self.stride)\n","        bins = np.concatenate([starts, starts + self.sample_bins], axis=1) if n>0 else np.zeros((0,2), dtype=int)\n","        return (bins * self.res).astype(int)\n","\n","    def _mask(self, intervals, omit_regions):\n","        if omit_regions is None or len(omit_regions)==0: return intervals.tolist()\n","        valid = []\n","        for s,e in intervals:\n","            if int(np.sum((s <= omit_regions[:,1]) & (omit_regions[:,0] <= e))) == 0:\n","                valid.append([int(s), int(e)])\n","        return valid\n","\n","    def _check_lengths(self):\n","        if len(self.genomic_features)>0:\n","            f0 = self.genomic_features[0].length(self.chr_name)\n","            assert len(self.seq) == f0, f\"Sequence {len(self.seq)} vs first feature {f0} mismatch.\"\n","        dna_bins = len(self.seq) / self.res\n","        hic_bins = len(self.mat)\n","        assert abs(dna_bins - hic_bins) < 2, f\"DNA bins {dna_bins} vs Hi-C bins {hic_bins} mismatch.\"\n","\n","# ================================================================\n","# Model + hooks\n","# ================================================================\n","class SeqEncoder(nn.Module):\n","    def __init__(self, in_channels=4, emb_dim=DNA_EMB_DIM):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=15, padding=7)\n","        self.conv2 = nn.Conv1d(64, 128, kernel_size=7, padding=3)\n","        self.proj  = nn.Conv1d(128, emb_dim, kernel_size=1)\n","    def forward(self, x, res_bp=RES_BP, l_bins=L_BINS):\n","        L_bp = x.shape[-1]\n","        eff  = l_bins * res_bp\n","        if L_bp > eff:\n","            x = x[..., :eff]\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = self.proj(x)                    # [B,D,eff]\n","        B,D,L = x.shape\n","        x = x.view(B, D, l_bins, res_bp).mean(dim=-1)   # [B,D,L_bins]\n","        return x.transpose(1,2).contiguous()            # [B,L_bins,D]\n","\n","class EpiEncoder(nn.Module):\n","    def __init__(self, in_dim=2, emb_dim=EPI_EMB_DIM):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(in_dim, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, emb_dim)\n","        )\n","    def forward(self, epi_bins):\n","        B,L,F = epi_bins.shape\n","        return self.net(epi_bins.view(B*L, F)).view(B, L, -1)\n","\n","class FusionHead(nn.Module):\n","    def __init__(self, emb_dim=min(DNA_EMB_DIM, EPI_EMB_DIM)):\n","        super().__init__()\n","        self.fuse = nn.Linear(emb_dim*2, emb_dim)\n","        self.out  = nn.Linear(emb_dim, 1)\n","    def forward(self, dna_emb, epi_emb):\n","        D = min(dna_emb.shape[-1], epi_emb.shape[-1])\n","        if dna_emb.shape[-1] != D: dna_emb = dna_emb[..., :D]\n","        if epi_emb.shape[-1] != D: epi_emb = epi_emb[..., :D]\n","        fused = torch.cat([dna_emb, epi_emb], dim=-1)\n","        fused = F.relu(self.fuse(fused))\n","        return fused, self.out(fused)\n","\n","class ConvTransModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.seq_encoder = SeqEncoder()\n","        self.epi_encoder = EpiEncoder()\n","        self.fusion_head = FusionHead()\n","    def forward(self, x_base4, x_epi, res_bp=RES_BP, l_bins=L_BINS):\n","        dna_emb = self.seq_encoder(x_base4, res_bp, l_bins)\n","        epi_emb = self.epi_encoder(x_epi)\n","        fused, _ = self.fusion_head(dna_emb, epi_emb)\n","        return {\"dna_emb\": dna_emb, \"epi_emb\": epi_emb, \"fused\": fused}\n","\n","def register_hooks(model):\n","    caches = {}\n","    def mk(name):\n","        def _hook(_, __, out): caches[name] = out.detach()\n","        return _hook\n","    model.seq_encoder.register_forward_hook(mk(\"dna_emb\"))\n","    model.epi_encoder.register_forward_hook(mk(\"epi_emb\"))\n","    return caches\n","\n","def onehot5_to_base4(seq_onehot5: np.ndarray) -> np.ndarray:\n","    a = seq_onehot5[:,0:1]; t = seq_onehot5[:,1:2]\n","    c = seq_onehot5[:,2:3]; g = seq_onehot5[:,3:4]\n","    return np.concatenate([a,c,g,t], axis=1).astype(np.float32)  # [L,4]\n","\n","# ================================================================\n","# Main (per-chrom loop + chr in filenames)\n","# ================================================================\n","def main():\n","    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","    assert os.path.isdir(DNA_DIR)\n","    assert os.path.isdir(HIC_DIR)\n","\n","    # Ensure genomic_features live under CELLTYPE_ROOT\n","    Path(f\"{CELLTYPE_ROOT}/genomic_features\").mkdir(parents=True, exist_ok=True)\n","    for src in [ATAC_BW, CTCF_BW]:\n","        expected = f\"{CELLTYPE_ROOT}/genomic_features/{Path(src).name}\"\n","        if os.path.abspath(src) != os.path.abspath(expected) and not os.path.exists(expected):\n","            import shutil; shutil.copy2(src, expected)\n","\n","    feat_dicts = {\n","        \"ctcf_log2fc\": {\"file_name\": Path(CTCF_BW).name, \"norm\": None},\n","        \"atac\":        {\"file_name\": Path(ATAC_BW).name,  \"norm\": \"log\"},\n","    }\n","    feature_list = [\n","        GenomicFeature(f\"{CELLTYPE_ROOT}/genomic_features/{Path(d['file_name']).name}\", d['norm'])\n","        for d in feat_dicts.values()\n","    ]\n","\n","    # Omit regions (if present)\n","    omit_dict = {}\n","    if CENTROTELO_BED and os.path.exists(CENTROTELO_BED):\n","        df = pd.read_csv(CENTROTELO_BED, sep=\"\\t\", names=[\"chr\",\"start\",\"end\"])\n","        for k,v in df.groupby(\"chr\"):\n","            omit_dict[k] = v[[\"start\",\"end\"]].to_numpy(dtype=int)\n","\n","    # Open bigWigs once\n","    bw_atac = pbw.open(ATAC_BW)\n","    bw_ctcf = pbw.open(CTCF_BW)\n","\n","    # Model\n","    model = ConvTransModel().to(device).eval()\n","    if CKPT_PATH and os.path.exists(CKPT_PATH):\n","        state = torch.load(CKPT_PATH, map_location=\"cpu\")\n","        model.load_state_dict(state.get(\"state_dict\", state), strict=False)\n","        print(\"Loaded checkpoint:\", CKPT_PATH)\n","    else:\n","        print(\"No checkpoint provided; embeddings will be untrained/random.\")\n","    caches = register_hooks(model)\n","\n","    # Chromosome order: 1..22, X, Y\n","    chr_list = [f\"chr{i}\" for i in range(1,23)] + [\"chrX\",\"chrY\"]\n","\n","    for chr_name in chr_list:\n","        print(f\"\\n===== Processing {chr_name} =====\")\n","        if not os.path.exists(f\"{DNA_DIR}/{chr_name}.fa.gz\"):\n","            print(f\"Skipping {chr_name}: missing {DNA_DIR}/{chr_name}.fa.gz\")\n","            continue\n","        if not os.path.exists(f\"{HIC_DIR}/{chr_name}.npz\"):\n","            print(f\"Skipping {chr_name}: missing {HIC_DIR}/{chr_name}.npz\")\n","            continue\n","\n","        ds = ChromosomeDataset(\n","            CELLTYPE_ROOT,\n","            chr_name,\n","            omit_dict.get(chr_name, None),\n","            feature_list,\n","            res_bp=RES_BP\n","        )\n","        total = len(ds)\n","        if total == 0:\n","            print(f\"{chr_name}: 0 windows (likely short chromosome or masked regions).\")\n","            continue\n","        max_n = total if (MAX_WINDOWS_PER_CHR is None) else min(MAX_WINDOWS_PER_CHR, total)\n","        print(f\"{chr_name}: {max_n}/{total} windows\")\n","\n","        shard_rows, shard_id = [], 0\n","        def flush():\n","            nonlocal shard_rows, shard_id\n","            if not shard_rows: return\n","            df = pd.DataFrame(shard_rows)\n","            out_path = os.path.join(OUT_DIR, f\"embeddings_{chr_name}_{shard_id:05d}.parquet\")\n","            df.to_parquet(out_path, index=False)\n","            print(f\"Wrote {out_path} ({len(df)} rows)\")\n","            shard_id += 1\n","            shard_rows = []\n","\n","        for idx in range(max_n):\n","            seq5, _feat_placeholder, _mat256, win_start, win_end = ds[idx]\n","            # DNA -> base4 -> GPU\n","            base4 = onehot5_to_base4(seq5)                       # [L_bp,4]\n","            x_base = torch.from_numpy(base4.T).unsqueeze(0).to(device)\n","\n","            # Epi (nBins= L_BINS)\n","            atac_vals = bw_atac.stats(chr_name, int(win_start), int(win_end), nBins=L_BINS, type=\"mean\")\n","            ctcf_vals = bw_ctcf.stats(chr_name, int(win_start), int(win_end), nBins=L_BINS, type=\"mean\")\n","            atac = np.log1p(np.nan_to_num(np.array(atac_vals, dtype=np.float32), 0.0))\n","            ctcf = np.nan_to_num(np.array(ctcf_vals, dtype=np.float32), 0.0)\n","            if atac.size != L_BINS or ctcf.size != L_BINS:\n","                raise ValueError(f\"{chr_name}:{win_start}-{win_end} expected {L_BINS} bins, got ATAC={atac.size}, CTCF={ctcf.size}\")\n","            epi = np.stack([atac, ctcf], axis=-1).astype(np.float32)  # [L_BINS,2]\n","            x_epi = torch.from_numpy(epi).unsqueeze(0).to(device)\n","\n","            # Forward\n","            with torch.no_grad():\n","                _ = model(x_base, x_epi, RES_BP, L_BINS)\n","            dna_emb = caches[\"dna_emb\"].detach().cpu().numpy()[0]   # [L_BINS, D1]\n","            epi_emb = caches[\"epi_emb\"].detach().cpu().numpy()[0]   # [L_BINS, D2]\n","\n","            # Rows\n","            for l in range(L_BINS):\n","                bstart = int(win_start + l*RES_BP)\n","                bend   = bstart + RES_BP\n","                shard_rows.append({\n","                    \"assembly\": ASSEMBLY,\n","                    \"celltype\": CELLTYPE,\n","                    \"chr\": chr_name,\n","                    \"win_start\": int(win_start),\n","                    \"win_end\": int(win_end),\n","                    \"bin_idx\": int(l),\n","                    \"bin_start\": bstart,\n","                    \"bin_end\": bend,\n","                    \"dna_emb\": dna_emb[l].astype(np.float32).tolist(),\n","                    \"epi_emb\": epi_emb[l].astype(np.float32).tolist()\n","                })\n","            if len(shard_rows) >= ROWS_PER_SHARD:\n","                flush()\n","            if (idx+1) % 50 == 0 or (idx+1) == max_n:\n","                print(f\"{chr_name}: processed {idx+1}/{max_n} windows\")\n","\n","        flush()  # last shard for this chromosome\n","\n","    # cleanup\n","    print(\"\\nAll chromosomes done.\")\n","    torch.cuda.empty_cache()\n","    try:\n","        bw_atac.close(); bw_ctcf.close()\n","    except: pass\n","\n","# Run\n","main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Guzn_N01Eysh","executionInfo":{"status":"ok","timestamp":1762988685312,"user_tz":300,"elapsed":4013941,"user":{"displayName":"Sneha Bapana","userId":"06343812349805612711"}},"outputId":"0bc3b8b7-6ec9-4035-a004-fdf8a195234d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Feature path: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/genomic_features/ctcf_log2fc.bw\n","Normalization status: None\n","Feature path: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/genomic_features/atac.bw\n","Normalization status: log\n","No checkpoint provided; embeddings will be untrained/random.\n","\n","===== Processing chr1 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr1.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr1.npz\n","chr1: 385/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00000.parquet (10032 rows)\n","chr1: processed 50/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00001.parquet (10032 rows)\n","chr1: processed 100/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00002.parquet (10032 rows)\n","chr1: processed 150/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00003.parquet (10032 rows)\n","chr1: processed 200/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00004.parquet (10032 rows)\n","chr1: processed 250/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00005.parquet (10032 rows)\n","chr1: processed 300/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00006.parquet (10032 rows)\n","chr1: processed 350/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00007.parquet (10032 rows)\n","chr1: processed 385/385 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr1_00008.parquet (209 rows)\n","\n","===== Processing chr2 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr2.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr2.npz\n","chr2: 375/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00000.parquet (10032 rows)\n","chr2: processed 50/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00001.parquet (10032 rows)\n","chr2: processed 100/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00002.parquet (10032 rows)\n","chr2: processed 150/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00003.parquet (10032 rows)\n","chr2: processed 200/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00004.parquet (10032 rows)\n","chr2: processed 250/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00005.parquet (10032 rows)\n","chr2: processed 300/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00006.parquet (10032 rows)\n","chr2: processed 350/375 windows\n","chr2: processed 375/375 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr2_00007.parquet (8151 rows)\n","\n","===== Processing chr3 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr3.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr3.npz\n","chr3: 302/302 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr3_00000.parquet (10032 rows)\n","chr3: processed 50/302 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr3_00001.parquet (10032 rows)\n","chr3: processed 100/302 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr3_00002.parquet (10032 rows)\n","chr3: processed 150/302 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr3_00003.parquet (10032 rows)\n","chr3: processed 200/302 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr3_00004.parquet (10032 rows)\n","chr3: processed 250/302 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr3_00005.parquet (10032 rows)\n","chr3: processed 300/302 windows\n","chr3: processed 302/302 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr3_00006.parquet (2926 rows)\n","\n","===== Processing chr4 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr4.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr4.npz\n","chr4: 291/291 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr4_00000.parquet (10032 rows)\n","chr4: processed 50/291 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr4_00001.parquet (10032 rows)\n","chr4: processed 100/291 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr4_00002.parquet (10032 rows)\n","chr4: processed 150/291 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr4_00003.parquet (10032 rows)\n","chr4: processed 200/291 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr4_00004.parquet (10032 rows)\n","chr4: processed 250/291 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr4_00005.parquet (10032 rows)\n","chr4: processed 291/291 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr4_00006.parquet (627 rows)\n","\n","===== Processing chr5 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr5.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr5.npz\n","chr5: 274/274 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr5_00000.parquet (10032 rows)\n","chr5: processed 50/274 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr5_00001.parquet (10032 rows)\n","chr5: processed 100/274 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr5_00002.parquet (10032 rows)\n","chr5: processed 150/274 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr5_00003.parquet (10032 rows)\n","chr5: processed 200/274 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr5_00004.parquet (10032 rows)\n","chr5: processed 250/274 windows\n","chr5: processed 274/274 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr5_00005.parquet (7106 rows)\n","\n","===== Processing chr6 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr6.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr6.npz\n","chr6: 259/259 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr6_00000.parquet (10032 rows)\n","chr6: processed 50/259 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr6_00001.parquet (10032 rows)\n","chr6: processed 100/259 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr6_00002.parquet (10032 rows)\n","chr6: processed 150/259 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr6_00003.parquet (10032 rows)\n","chr6: processed 200/259 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr6_00004.parquet (10032 rows)\n","chr6: processed 250/259 windows\n","chr6: processed 259/259 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr6_00005.parquet (3971 rows)\n","\n","===== Processing chr7 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr7.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr7.npz\n","chr7: 239/239 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr7_00000.parquet (10032 rows)\n","chr7: processed 50/239 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr7_00001.parquet (10032 rows)\n","chr7: processed 100/239 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr7_00002.parquet (10032 rows)\n","chr7: processed 150/239 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr7_00003.parquet (10032 rows)\n","chr7: processed 200/239 windows\n","chr7: processed 239/239 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr7_00004.parquet (9823 rows)\n","\n","===== Processing chr8 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr8.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr8.npz\n","chr8: 216/216 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr8_00000.parquet (10032 rows)\n","chr8: processed 50/216 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr8_00001.parquet (10032 rows)\n","chr8: processed 100/216 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr8_00002.parquet (10032 rows)\n","chr8: processed 150/216 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr8_00003.parquet (10032 rows)\n","chr8: processed 200/216 windows\n","chr8: processed 216/216 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr8_00004.parquet (5016 rows)\n","\n","===== Processing chr9 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr9.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr9.npz\n","chr9: 205/205 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr9_00000.parquet (10032 rows)\n","chr9: processed 50/205 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr9_00001.parquet (10032 rows)\n","chr9: processed 100/205 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr9_00002.parquet (10032 rows)\n","chr9: processed 150/205 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr9_00003.parquet (10032 rows)\n","chr9: processed 200/205 windows\n","chr9: processed 205/205 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr9_00004.parquet (2717 rows)\n","\n","===== Processing chr10 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr10.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr10.npz\n","chr10: 198/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr10_00000.parquet (10032 rows)\n","chr10: processed 50/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr10_00001.parquet (10032 rows)\n","chr10: processed 100/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr10_00002.parquet (10032 rows)\n","chr10: processed 150/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr10_00003.parquet (10032 rows)\n","chr10: processed 198/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr10_00004.parquet (1254 rows)\n","\n","===== Processing chr11 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr11.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr11.npz\n","chr11: 198/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr11_00000.parquet (10032 rows)\n","chr11: processed 50/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr11_00001.parquet (10032 rows)\n","chr11: processed 100/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr11_00002.parquet (10032 rows)\n","chr11: processed 150/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr11_00003.parquet (10032 rows)\n","chr11: processed 198/198 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr11_00004.parquet (1254 rows)\n","\n","===== Processing chr12 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr12.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr12.npz\n","chr12: 197/197 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr12_00000.parquet (10032 rows)\n","chr12: processed 50/197 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr12_00001.parquet (10032 rows)\n","chr12: processed 100/197 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr12_00002.parquet (10032 rows)\n","chr12: processed 150/197 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr12_00003.parquet (10032 rows)\n","chr12: processed 197/197 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr12_00004.parquet (1045 rows)\n","\n","===== Processing chr13 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr13.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr13.npz\n","chr13: 167/167 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr13_00000.parquet (10032 rows)\n","chr13: processed 50/167 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr13_00001.parquet (10032 rows)\n","chr13: processed 100/167 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr13_00002.parquet (10032 rows)\n","chr13: processed 150/167 windows\n","chr13: processed 167/167 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr13_00003.parquet (4807 rows)\n","\n","===== Processing chr14 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr14.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr14.npz\n","chr14: 155/155 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr14_00000.parquet (10032 rows)\n","chr14: processed 50/155 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr14_00001.parquet (10032 rows)\n","chr14: processed 100/155 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr14_00002.parquet (10032 rows)\n","chr14: processed 150/155 windows\n","chr14: processed 155/155 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr14_00003.parquet (2299 rows)\n","\n","===== Processing chr15 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr15.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr15.npz\n","chr15: 145/145 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr15_00000.parquet (10032 rows)\n","chr15: processed 50/145 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr15_00001.parquet (10032 rows)\n","chr15: processed 100/145 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr15_00002.parquet (10032 rows)\n","chr15: processed 145/145 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr15_00003.parquet (209 rows)\n","\n","===== Processing chr16 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr16.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr16.npz\n","chr16: 127/127 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr16_00000.parquet (10032 rows)\n","chr16: processed 50/127 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr16_00001.parquet (10032 rows)\n","chr16: processed 100/127 windows\n","chr16: processed 127/127 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr16_00002.parquet (6479 rows)\n","\n","===== Processing chr17 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr17.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr17.npz\n","chr17: 113/113 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr17_00000.parquet (10032 rows)\n","chr17: processed 50/113 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr17_00001.parquet (10032 rows)\n","chr17: processed 100/113 windows\n","chr17: processed 113/113 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr17_00002.parquet (3553 rows)\n","\n","===== Processing chr18 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr18.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr18.npz\n","chr18: 105/105 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr18_00000.parquet (10032 rows)\n","chr18: processed 50/105 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr18_00001.parquet (10032 rows)\n","chr18: processed 100/105 windows\n","chr18: processed 105/105 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr18_00002.parquet (1881 rows)\n","\n","===== Processing chr19 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr19.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr19.npz\n","chr19: 73/73 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr19_00000.parquet (10032 rows)\n","chr19: processed 50/73 windows\n","chr19: processed 73/73 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr19_00001.parquet (5225 rows)\n","\n","===== Processing chr20 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr20.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr20.npz\n","chr20: 82/82 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr20_00000.parquet (10032 rows)\n","chr20: processed 50/82 windows\n","chr20: processed 82/82 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr20_00001.parquet (7106 rows)\n","\n","===== Processing chr21 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr21.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr21.npz\n","chr21: 55/55 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr21_00000.parquet (10032 rows)\n","chr21: processed 50/55 windows\n","chr21: processed 55/55 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr21_00001.parquet (1463 rows)\n","\n","===== Processing chr22 =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chr22.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chr22.npz\n","chr22: 63/63 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr22_00000.parquet (10032 rows)\n","chr22: processed 50/63 windows\n","chr22: processed 63/63 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chr22_00001.parquet (3135 rows)\n","\n","===== Processing chrX =====\n","Reading sequence: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/../dna_sequence/chrX.fa.gz\n","Reading Hi-C: /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chrX.npz\n","chrX: 231/231 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chrX_00000.parquet (10032 rows)\n","chrX: processed 50/231 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chrX_00001.parquet (10032 rows)\n","chrX: processed 100/231 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chrX_00002.parquet (10032 rows)\n","chrX: processed 150/231 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chrX_00003.parquet (10032 rows)\n","chrX: processed 200/231 windows\n","chrX: processed 231/231 windows\n","Wrote /content/drive/MyDrive/ML4GEN DATA/data - IMR90/embeddings2_out/embeddings_chrX_00004.parquet (8151 rows)\n","\n","===== Processing chrY =====\n","Skipping chrY: missing /content/drive/MyDrive/ML4GEN DATA/data - IMR90/hg38/imr90/hic_matrix/chrY.npz\n","\n","All chromosomes done.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XAR8-FrxvUjF"},"execution_count":null,"outputs":[]}]}